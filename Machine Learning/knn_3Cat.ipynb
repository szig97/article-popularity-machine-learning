{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Data Partitioned into Three Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_file = \"../Data/threecleaneddata.csv\"\n",
    "premise_df = pd.read_csv(premise_file)\n",
    "premise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneccseary columns\n",
    "data=premise_df.drop([\"Unnamed: 0\", \"url\", \"Shares\", \"Category\"], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the target column for dataset\n",
    "target=premise_df[\"Category\"]\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data set into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model without scaling and No One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 50, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, 50, 2), train_scores, marker='o', color=\"cornflowerblue\", label=\"Training Data\")\n",
    "plt.plot(range(1, 50, 2), test_scores, marker=\"x\", color=\"firebrick\", label=\"Testing Data\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.title(\"Accuracy of Training Set vs Test Set (Non-Scaled Values)\")\n",
    "plt.ylim([0,1.2])\n",
    "plt.grid()\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"../graphics/knn_graphics/3cat_noScaling_noOHE.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=43)\n",
    "knn.fit(X_train, y_train)\n",
    "print('k=43 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model with scaling and No One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores_scaled = []\n",
    "test_scores_scaled = []\n",
    "for k in range(1, 36, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores_scaled.append(train_score)\n",
    "    test_scores_scaled.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 36, 2), train_scores_scaled, marker='o', color=\"cornflowerblue\", label=\"Training Data\")\n",
    "plt.plot(range(1, 36, 2), test_scores_scaled, marker=\"x\", color=\"firebrick\", label=\"Testing Data\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.title(\"Accuracy of Training Set vs Test Set (Scaled Values)\")\n",
    "plt.ylim([0,1.2])\n",
    "plt.grid()\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"../graphics/knn_graphics/3cat_Scaling_noOHE.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 31 provides the best accuracy where the classifier starts to stablize\n",
    "knn = KNeighborsClassifier(n_neighbors=33)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=33 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_scaled))\n",
    "print(classification_report(y_test, y_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model with One-Hot-Encoding and without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores_categorical = []\n",
    "test_scores_categorical = []\n",
    "for k in range(1, 75, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train_categorical)\n",
    "    train_score = knn.score(X_train, y_train_categorical)\n",
    "    test_score = knn.score(X_test, y_test_categorical)\n",
    "    train_scores_categorical.append(train_score)\n",
    "    test_scores_categorical.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 75, 2), train_scores_categorical, marker='o', color=\"cornflowerblue\", label=\"Training Data\")\n",
    "plt.plot(range(1, 75, 2), test_scores_categorical, marker=\"x\", color=\"firebrick\", label=\"Testing Data\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.title(\"Accuracy of Training Set vs Test Set (One-Hot Encoded and Non-Scaled Values)\")\n",
    "plt.ylim([0,1.2])\n",
    "plt.grid()\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"../graphics/knn_graphics/3cat_noScaling_OHE.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 31 provides the best accuracy where the classifier starts to stablize\n",
    "knn = KNeighborsClassifier(n_neighbors=63)\n",
    "knn.fit(X_train, y_train_categorical)\n",
    "print('k=63 Test Acc: %.3f' % knn.score(X_test, y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ohe = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model with scaling and One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores_scaled_categorical = []\n",
    "test_scores_scaled_categorical = []\n",
    "for k in range(1, 36, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train_categorical)\n",
    "    train_score = knn.score(X_train_scaled, y_train_categorical)\n",
    "    test_score = knn.score(X_test_scaled, y_test_categorical)\n",
    "    train_scores_scaled_categorical.append(train_score)\n",
    "    test_scores_scaled_categorical.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 36, 2), train_scores_scaled_categorical, marker='o', color=\"cornflowerblue\", label=\"Training Data\")\n",
    "plt.plot(range(1, 36, 2), test_scores_scaled_categorical, marker=\"x\", color=\"firebrick\", label=\"Testing Data\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.title(\"Accuracy of Training Set vs Test Set (One-Hot Encoded and Scaled Values)\")\n",
    "plt.ylim([0,1.2])\n",
    "plt.grid()\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"../graphics/knn_graphics/3cat_Scaling_OHE.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
